{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd06dae6",
   "metadata": {},
   "source": [
    "# EL-HAMDAOUI MAROUANE | IAGI CI-2\n",
    "# Partie 1 : Capteurs et Mouvements\n",
    "\n",
    "Dans cette partie, vous allez implémenter les fonctions de base permettant au robot de percevoir son environnement et de se déplacer.\n",
    "\n",
    "## Question 1.1 : Implémentation des fonctions de base\n",
    "\n",
    "Implémentez les trois fonctions suivantes :\n",
    "\n",
    "- **in_bounds(G, i, j)** : vérifie si la position (i, j) est dans les limites de la grille G\n",
    "- **is_wall(G, i, j)** : vérifie si la position (i, j) est un mur (valeur 1) ou hors limites\n",
    "- **move(i, j, d)** : calcule la nouvelle position après un déplacement dans la direction d\n",
    "\n",
    "**Note :** Les directions sont codées par : `DIRS = [(-1,0), (0,1), (1,0), (0,-1)]` pour N, E, S, O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abdfe53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRS = [(-1,0), (0,1), (1,0), (0,-1)] # N, E, S, O\n",
    "\n",
    "def in_bounds(G, i, j):\n",
    "    return 0 <= i < len(G) and 0 <= j < len(G[0])\n",
    "\n",
    "def is_wall(G, i, j):\n",
    "    return not in_bounds(G, i, j) or G[i][j] == 1\n",
    "\n",
    "def move(i, j, d):\n",
    "    return i + DIRS[d][0], j + DIRS[d][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4ddf63",
   "metadata": {},
   "source": [
    "## Question 1.2 : Différence entre in_bounds et is_wall\n",
    "\n",
    "Quelle est la différence entre les fonctions `in_bounds` et `is_wall` ? Pourquoi avons-nous besoin des deux ?\n",
    "\n",
    "**Réponse :**\n",
    "- **`in_bounds(G, i, j)`** : vérifie uniquement si les coordonnées (i, j) sont à l'intérieur des limites de la grille (indices valides)\n",
    "- **`is_wall(G, i, j)`** : vérifie si une position **valide** contient un mur (valeur 1 dans la grille)\n",
    "\n",
    "Nous avons besoin des deux fonctions car :\n",
    "- `in_bounds` évite les erreurs d'accès hors limites (IndexError)\n",
    "- `is_wall` identifie les obstacles ou bien la limite de la grille\n",
    "\n",
    "## Question 1.3 : Comportement hors limites\n",
    "\n",
    "Que se passe-t-il si le robot essaie de sortir de la grille ? Comment votre implémentation gère-t-elle ce cas ?\n",
    "\n",
    "**Réponse :**\n",
    "L'implémentation actuelle ne gère pas explicitement ce cas :\n",
    "- La fonction `move()` calcule simplement la nouvelle position sans vérification\n",
    "- Si le robot essaie de sortir, `is_wall()` tentera d'accéder à `G[i][j]` avec des indices invalides, ce qui causera une **IndexError**\n",
    "- Pour gérer correctement ce cas, il faudrait vérifier `in_bounds()` **avant** d'appeler `is_wall()`, ou modifier `is_wall()` pour retourner `True` (obstacle) si la position est hors limites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52548ae5",
   "metadata": {},
   "source": [
    "# Partie 2 : Décision Locale (Règles Simples)\n",
    "Dans cette partie, vous allez implémenter la stratégie de décision de l'agent réactif basée sur la\n",
    "règle de la \"main droite\".\n",
    "\n",
    "## Question 2.1: Implémentation de choose_action\n",
    "Implémentez la fonction choose_action(G, i, j, d) qui choisit la prochaine direction selon la\n",
    "priorité : droite →avant →gauche →demi-tour.\n",
    "`Stratégie \"main droite\" : priorité droite > avant > gauche > demi-tour`\n",
    "\n",
    "```python\n",
    "def choose_action(G, i, j, d):\n",
    "return d\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d15387f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d will be an index of DIRS\n",
    "# 0 -> North, 1 -> East, 2 -> South, 3 -> West\n",
    "def choose_action(G, i, j, d):\n",
    "    actions = [\"right\", \"forward\", \"left\", \"back\"]\n",
    "    dirs = [1, 0, -1, 2]\n",
    "    k = 0\n",
    "\n",
    "    for action in actions:\n",
    "        new_d = (d + dirs[k]) % 4\n",
    "        new_i, new_j = move(i, j, new_d)\n",
    "        \n",
    "        if not is_wall(G, new_i, new_j):\n",
    "            return action\n",
    "        \n",
    "        k += 1\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf54921",
   "metadata": {},
   "source": [
    "## Question 2.2 : Description de la stratégie\n",
    "Décrivez en vos propres mots la stratégie utilisée par l'agent pour choisir sa direction.\n",
    "\n",
    "**Réponse :**\n",
    "L'agent utilise une stratégie de type \"main droite\" pour naviguer dans le labyrinthe. À chaque étape, il tente de tourner à droite par rapport à sa direction actuelle. Si la case à droite est libre, il se déplace dans cette direction. Si la case à droite est bloquée, il essaie d'aller tout droit. Si cette direction est également bloquée, il tente de tourner à gauche. Enfin, si toutes les directions sont bloquées, il effectue un demi-tour pour revenir sur ses pas. Cette stratégie permet à l'agent de suivre les murs à sa droite et d'explorer le labyrinthe de manière systématique.\n",
    "\n",
    "## Question 2.3 : Ordre de priorité\n",
    "Pourquoi tester les directions dans l'ordre [droite, avant, gauche, demi-tour] ? Qu'est-ce que cela\n",
    "simule ?\n",
    "\n",
    "**Réponse :**\n",
    "L'ordre de priorité simule la stratégie de la \"main droite\", où l'agent suit le mur à sa droite. Cette approche est couramment utilisée dans les labyrinthes car elle garantit que l'agent finira par explorer toutes les parties accessibles du labyrinthe, à condition que le labyrinthe soit simplement connecté.\n",
    "\n",
    "## Question 2.4 : Cas bloqué\n",
    "Que se passe-t-il si toutes les directions sont bloquées (murs partout) ? Comment votre fonction\n",
    "gère-t-elle ce cas ?\n",
    "\n",
    "**Réponse :**\n",
    "Si toutes les directions sont bloquées, l'agent ne peut pas se déplacer. Dans ce cas, la fonction `choose_action` renvoie `None`, indiquant qu'aucune action n'est possible. Cela permet à la boucle de simulation de détecter que l'agent est coincé et d'arrêter la simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1260f718",
   "metadata": {},
   "source": [
    "## Question 2.5 : Variante \"main gauche\"\n",
    "Proposez une modification de la fonction choose_action pour implémenter une stratégie \"main\n",
    "gauche\" au lieu de \"main droite\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c510d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_action_G(G, i, j, d):\n",
    "    actions = [\"left\", \"forward\", \"right\", \"back\"] \n",
    "    dirs = [-1, 0, 1, 2]\n",
    "    idx = 0\n",
    "\n",
    "    for action in actions:\n",
    "        new_d = (d + dirs[idx]) % 4\n",
    "        ni, nj = move(i, j, new_d)\n",
    "        \n",
    "        if not is_wall(G, ni, nj):\n",
    "            return action\n",
    "        \n",
    "        idx += 1\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2644718a",
   "metadata": {},
   "source": [
    "# Partie 3 : Simulation du Déplacement\n",
    "\n",
    "Dans cette partie, vous allez implémenter la boucle principale de simulation qui fait avancer le\n",
    "robot jusqu'au but (ou jusqu'à atteindre le nombre maximum d'étapes).\n",
    "\n",
    "## Question 3.1 : Implémentation de run_agent\n",
    "Implémentez la fonction run_agent(G, start, goal, d0=0, max_steps=200) qui simule le\n",
    "déplacement de l'agent.\n",
    "\n",
    "```python\n",
    "def run_agent(G, start, goal, d0=0, max_steps=200):\n",
    "    return path\n",
    "\n",
    "path = run_agent(LAB, S, G, d0=1)\n",
    "print('Longueur du chemin :', len(path))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7eec37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent(G: list, start: tuple, goal: tuple, d0=0, max_steps=200):\n",
    "    i, j = start[0], start[1]\n",
    "    d = d0\n",
    "    steps = 0\n",
    "    path = []\n",
    "\n",
    "    if is_wall(G, i, j):\n",
    "        print(\"Starting point is a wall\")\n",
    "        return path\n",
    "\n",
    "    while (i, j) != (goal[0], goal[1]):\n",
    "        if steps >= max_steps:\n",
    "            print(\"Max steps reached\")\n",
    "            return path\n",
    "\n",
    "        action = choose_action(G, i, j, d)\n",
    "        if action is None:\n",
    "            print(\"No possible action\")\n",
    "            return path\n",
    "        \n",
    "        path.append(action)\n",
    "        \n",
    "        match action:\n",
    "            case \"right\":\n",
    "                d = (d + 1) % 4\n",
    "            case \"left\":\n",
    "                d = (d - 1) % 4\n",
    "            case \"back\":\n",
    "                d = (d + 2) % 4\n",
    "\n",
    "        i, j = move(i, j, d)\n",
    "        steps += 1\n",
    "        print(f\"Step {steps}: position=({i},{j}), direction={d}, action={action}\")\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de543da",
   "metadata": {},
   "source": [
    "## Question 3.2 : Résultats de l'exécution\n",
    "\n",
    "Exécutez le programme plusieurs fois. Notez :\n",
    "- Le nombre d'étapes pour atteindre le but\n",
    "- La longueur du chemin parcouru\n",
    "- Le comportement observé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dec2f54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: position=(2,1), direction=2, action=right\n",
      "Step 2: position=(3,1), direction=2, action=forward\n",
      "Step 3: position=(4,1), direction=2, action=forward\n",
      "Step 4: position=(4,2), direction=1, action=left\n",
      "Step 5: position=(4,3), direction=1, action=forward\n",
      "Step 6: position=(5,3), direction=2, action=right\n",
      "Step 7: position=(6,3), direction=2, action=forward\n",
      "Step 8: position=(6,2), direction=3, action=right\n",
      "Step 9: position=(6,1), direction=3, action=forward\n",
      "Step 10: position=(6,2), direction=1, action=back\n",
      "Step 11: position=(6,3), direction=1, action=forward\n",
      "Step 12: position=(5,3), direction=0, action=left\n",
      "Step 13: position=(5,4), direction=1, action=right\n",
      "Step 14: position=(5,5), direction=1, action=forward\n",
      "Step 15: position=(6,5), direction=2, action=right\n",
      "Step 16: position=(6,6), direction=1, action=left\n",
      "['right', 'forward', 'forward', 'left', 'forward', 'right', 'forward', 'right', 'forward', 'back', 'forward', 'left', 'right', 'forward', 'right', 'left']\n",
      "Longueur du chemin : 16\n"
     ]
    }
   ],
   "source": [
    "LAB = [\n",
    "[1,1,1,1,1,1,1,1],\n",
    "[1,0,0,0,1,0,0,1],\n",
    "[1,0,1,0,0,0,1,1],\n",
    "[1,0,1,0,1,0,0,1],\n",
    "[1,0,0,0,1,1,0,1],\n",
    "[1,1,1,0,0,0,0,1],\n",
    "[1,0,0,0,1,0,0,1],\n",
    "[1,1,1,1,1,1,1,1]\n",
    "]\n",
    "\n",
    "S = (1, 1)\n",
    "G = (6, 6)\n",
    "\n",
    "path = run_agent(LAB, S, G, d0=1)\n",
    "print(path)\n",
    "print('Longueur du chemin :', len(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48baa858",
   "metadata": {},
   "source": [
    "### Question 3.3 : But atteint ?\n",
    "\n",
    "Le but a-t-il été atteint ? Si non, pourquoi ? Si oui, le chemin est-il optimal ?\n",
    "\n",
    "** Réponse :**\n",
    "Oui, le but a été atteint. Cependant, le chemin parcouru n'est pas optimal car l'agent suit une stratégie locale (main droite) qui ne garantit pas le chemin le plus court vers le but. L'agent peut faire des détours ou tourner en rond avant de trouver le but."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62abe0f",
   "metadata": {},
   "source": [
    "## Partie 4 : Visualisation du Chemin\n",
    "\n",
    "Pour mieux comprendre le comportement de l'agent, nous allons visualiser sa trajectoire sur la\n",
    "grille.\n",
    "\n",
    "### Question 4 : Implémentation de print_path\n",
    "\n",
    "Implémentez la fonction `print_path(G, path, S, goal)` qui affiche la grille avec :\n",
    "- 'S ' pour le départ\n",
    "- 'G ' pour le but\n",
    "- '█' pour les murs\n",
    "- 'V ' pour les cases visitées\n",
    "- ' ' (espaces) pour les cases libres non visitées\n",
    "\n",
    "```python\n",
    "def print_path(G, path, S, goal):\n",
    "print_path(LAB, path, S, G)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64fa4146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "████████\n",
      "█S     █    █\n",
      "█V █      ██\n",
      "█V █  █    █\n",
      "█V V V ██  █\n",
      "███V V V   █\n",
      "█V V V █V G █\n",
      "████████\n"
     ]
    }
   ],
   "source": [
    "def print_path(G, path, S, goal):\n",
    "    visited = set()\n",
    "    i, j = S\n",
    "    visited.add((i, j))\n",
    "    d = 1  # Initial direction (East)\n",
    "\n",
    "    for action in path:\n",
    "        match action:\n",
    "            case \"right\":\n",
    "                d = (d + 1) % 4\n",
    "            case \"left\":\n",
    "                d = (d - 1) % 4\n",
    "            case \"back\":\n",
    "                d = (d + 2) % 4\n",
    "\n",
    "        i, j = move(i, j, d)\n",
    "        visited.add((i, j))\n",
    "\n",
    "    for r in range(len(G)):\n",
    "        row_str = \"\"\n",
    "        for c in range(len(G[0])):\n",
    "            if (r, c) == S:\n",
    "                row_str += \"S \"\n",
    "            elif (r, c) == goal:\n",
    "                row_str += \"G \"\n",
    "            elif G[r][c] == 1:\n",
    "                row_str += \"█\"\n",
    "            elif (r, c) in visited:\n",
    "                row_str += \"V \"\n",
    "            else:\n",
    "                row_str += \"  \"\n",
    "        print(row_str)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "print_path(LAB, path, S, G)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8964cb6c",
   "metadata": {},
   "source": [
    "## Partie 5 : Analyse et Réflexion\n",
    "\n",
    "Cette dernière partie est consacrée à l'analyse critique du comportement de votre agent réactif.\n",
    "\n",
    "### Question 5.1 : Garantie d'atteindre le but\n",
    "\n",
    "L'agent atteint-il toujours le but ? Pourquoi ou pourquoi pas ? Donnez un exemple de configuration où il échouerait.\n",
    "\n",
    "**Réponse :**\n",
    "L'agent n'atteint pas toujours le but. La stratégie de la \"main droite\" peut conduire l'agent à tourner en rond dans certaines configurations de labyrinthe, notamment celles où le but est situé dans une zone isolée ou entourée de murs. Par exemple, si le labyrinthe a une boucle fermée autour du but, l'agent peut rester coincé à l'intérieur de cette boucle sans jamais trouver le chemin vers le but.\n",
    "\n",
    "### Question 5.2 : Problème des boucles infinies\n",
    "\n",
    "Que se passe-t-il si l'agent tourne en boucle (visite les mêmes cases indéfiniment) ? Comment pourriez-vous détecter ce problème ?\n",
    "\n",
    "**Réponse :**\n",
    "Si l'agent tourne en boucle, il visitera les mêmes cases indéfiniment sans atteindre le but. Pour détecter ce problème, on pourrait maintenir un historique des positions visitées par l'agent. Si l'agent revient à une position déjà visitée un certain nombre de fois, on peut conclure qu'il est en train de tourner en boucle. Une autre approche serait d'utiliser un compteur de mouvements sans progrès vers le but, et si ce compteur dépasse un seuil, on peut supposer que l'agent est coincé dans une boucle.\n",
    "\n",
    "### Question 5.3 : Besoin de mémoire\n",
    "\n",
    "L'agent a-t-il besoin d'une mémoire ? Si oui, quelle forme devrait-elle prendre ? Que devrait-il mémoriser ?\n",
    "\n",
    "**Réponse :**\n",
    "Oui, l'agent a besoin d'une mémoire pour éviter de tourner en boucle et pour améliorer son comportement. La mémoire pourrait prendre la forme d'une liste ou d'un ensemble des positions déjà visitées. L'agent devrait mémoriser les coordonnées des cases qu'il a déjà explorées, ainsi que peut-être la direction dans laquelle il se trouvait à chaque position. Cela lui permettrait de prendre des décisions plus informées, comme éviter de revenir sur ses pas ou de choisir des directions qui l'ont déjà conduit à des impasses.\n",
    "\n",
    "### Question 5.4 : Amélioration de la stratégie\n",
    "\n",
    "Comment pourriez-vous améliorer la stratégie de l'agent ? Proposez une solution utilisant un historique des positions visitées.\n",
    "\n",
    "**Réponse :**\n",
    "Pour améliorer la stratégie de l'agent, on pourrait implémenter une approche basée sur un historique des positions visitées. Par exemple, l'agent pourrait utiliser une structure de données telle qu'un ensemble pour stocker les positions déjà explorées. Lorsqu'il choisit une direction, il pourrait prioriser les directions qui mènent à des positions non visitées. De plus, l'agent pourrait utiliser un algorithme de recherche plus sophistiqué, comme A* ou Dijkstra, qui prend en compte l'ensemble des positions visitées pour trouver le chemin le plus court vers le but, plutôt que de se baser uniquement sur des règles locales."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
