{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I-Importer les biblioth√®ques et charger les donn√©es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous utilisons ici le jeu de donn√©es iris pour illustrer l'analyse PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Charger le jeu de donn√©es Iris\n",
    "iris = load_iris()\n",
    "X = iris.data  # Matrice des caract√©ristiques\n",
    "variables = iris.feature_names  # Noms des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standardisation des donn√©es\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer l'ACP\n",
    "pca = PCA(n_components=4)\n",
    "X_pca = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II-Calcul des variances expliqu√©es par chaque composante principale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance = pca.explained_variance_ratio_\n",
    "cumulative_variance = np.cumsum(explained_variance)\n",
    "\n",
    "# Affichage\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.bar(range(1, 5), explained_variance, alpha=0.6, label=\"Variance expliqu√©e\")\n",
    "plt.plot(range(1, 5), cumulative_variance, marker='o', linestyle='--', color='red', label=\"Variance cumul√©e\")\n",
    "plt.xlabel(\"Composantes principales\")\n",
    "plt.ylabel(\"Variance expliqu√©e\")\n",
    "plt.title(\"Variance expliqu√©e par les composantes principales\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette courbe montre combien d‚Äôinformation est conserv√©e en fonction du nombre de composantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Les pourcentages des variances expliqu√©es par les composantes:\", (explained_variance*100).round(2))\n",
    "print(\"La variance cumulative expliqu√©e est :\", cumulative_variance.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "\n",
    "<span style=\"color:blue\"> **D'apr√®s les valeurs de la variance cumulative expliqu√©e, on canstate qu'on peut concerver 96% de la variance globale dans un espace de deux dimensions** </span>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III-Calcul des qualit√©s de repr√©sentation des variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\"> **La qualit√© de repr√©sentation** d‚Äôune variable sur une composante (aussi appel√©e cos¬≤) est calcul√©e comme le carr√© des coefficients de la matrice des composantes divis√©s par la somme des coefficients au carr√© </span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Matrice des composantes principales (charges factorielles)\n",
    "loadings = pca.components_.T  # Transpos√©e pour aligner avec les variables initiales\n",
    "\n",
    "# Calcul des cos¬≤\n",
    "\n",
    "cos2 = (loadings ** 2) / np.sum(loadings ** 2, axis=1, keepdims=True)\n",
    "\n",
    "# Affichage\n",
    "cos2_df = pd.DataFrame(cos2, index=variables, columns=[f\"PC{i+1}\" for i in range(2)])\n",
    "print(\"Qualit√© de repr√©sentation (cos¬≤) des variables :\\n\", cos2_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpr√©tation : Plus un cos¬≤ est proche de 1, mieux la variable est repr√©sent√©e sur cette composante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV- Calcul des contributions des variables aux composantes principales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La contribution d‚Äôune variable √† une composante est donn√©e par : `Contribution= (Charge¬†factorielle¬≤/‚àëCharge¬†factorielle¬≤)*100`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contributions des variables\n",
    "contributions = (loadings ** 2) / np.sum(loadings ** 2, axis=0)\n",
    "\n",
    "# Affichage sous forme de DataFrame\n",
    "contrib_df = pd.DataFrame(contributions * 100, index=variables, columns=[f\"PC{i+1}\" for i in range(2)])\n",
    "print(\"\\nContributions des variables aux composantes principales :\\n\", contrib_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\"> **Interpr√©tation** : Les variables ayant les plus grandes contributions sont celles qui influencent le plus chaque composante. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V-Visualisation des r√©sultats\n",
    "### Cercles des corr√©lations\n",
    "\n",
    "- Les variables proches sont corr√©l√©es dans l'espace de projection.\n",
    "- Si elles sont oppos√©es, elles sont en relation inverse.\n",
    "- Si elles sont **loin du centre**, elles sont **bien repr√©sent√©es**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "for i in range(len(variables)):\n",
    "    ax.arrow(0, 0, loadings[i, 0], loadings[i, 1], head_width=0.05, head_length=0.05, color='b')# trace une fl√®che partant de (0,0) jusqu'aux coordonn√©es de la variable\n",
    "    plt.text(loadings[i, 0], loadings[i, 1], variables[i], fontsize=12)\n",
    "\n",
    "plt.xlim(-1, 1)\n",
    "plt.ylim(-1, 1)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(\"Cercle des corr√©lations (PC1 vs PC2)\")\n",
    "plt.axhline(0, color='grey', linestyle='--')\n",
    "plt.axvline(0, color='grey', linestyle='--')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projection des individus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=iris.target, palette=\"Set1\", alpha=0.8)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(\"Projection des individus (PC1 vs PC2)\")\n",
    "plt.axhline(0, color='grey', linestyle='--')\n",
    "plt.axvline(0, color='grey', linestyle='--')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpr√©tation :\n",
    "\n",
    "- Les points proches appartiennent √† des individus similaires.\n",
    "- Une s√©paration des classes peut √™tre visible si les premi√®res composantes capturent bien la variabilit√©."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI- Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Les pourcentages des variances expliqu√©es par les composantes:\", (explained_variance*100).round(2))\n",
    "print(\"La variance cumulative expliqu√©e est :\", cumulative_variance.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si l'on conserve deux composantes principales apr√®s une Analyse en Composantes Principales (ACP), plusieurs observations peuvent √™tre faites :\n",
    "\n",
    "1- Conservation de la variance globale : Les deux premi√®res composantes principales expliquent 96% de la variance totale, assurant ainsi une bonne repr√©sentation des donn√©es.\n",
    "\n",
    "2- Composante 1 (PC1) ‚Äì Axe principal des donn√©es : Elle capture 73% de l‚Äôinformation globale et est principalement form√©e par :\n",
    "\n",
    "- Sepal length (27%)    \n",
    "- Petal length (34%)    \n",
    "- Petal width (33%) \n",
    "\n",
    "3- Composante 2 (PC2) ‚Äì Variation compl√©mentaire : Elle explique 23% de l‚Äôinformation globale et est essentiellement port√©e par :\n",
    "\n",
    "- Sepal width (85%)\n",
    "\n",
    "**Conclusion** : La premi√®re composante (PC1) traduit une forte corr√©lation entre les mesures des p√©tales, tandis que la seconde (PC2) met en avant la variation de la largeur des s√©pales comme un facteur distinctif. Ensemble, ces deux composantes offrent une repr√©sentation fid√®le et compacte des donn√©es initiales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VII- Travail √† faire: Analyse en Composantes Principales (ACP) et Clustering K-Means sur le jeu de donn√©es D√©cathlon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objectifs :**\n",
    "\n",
    "- Appliquer une Analyse en Composantes Principales (ACP) pour r√©duire la dimensionnalit√© et interpr√©ter les principales sources de variation des performances des athl√®tes.\n",
    "\n",
    "- Utiliser le clustering K-Means pour segmenter les athl√®tes en groupes homog√®nes en fonction de leurs performances.    \n",
    "\n",
    "- Visualiser et interpr√©ter les r√©sultats pour comprendre les liens entre les disciplines et les profils d'athl√®tes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Contexte : Le jeu de donn√©es D√©cathlon**    \n",
    "Le jeu de donn√©es D√©cathlon contient les performances de plusieurs athl√®tes sur 10 disciplines de l‚Äô√©preuve du d√©cathlon. Chaque colonne repr√©sente une discipline (course, lancer, saut, etc.), et chaque ligne correspond √† un athl√®te.\n",
    "\n",
    "**Variables disponibles :**\n",
    "\n",
    "- √âpreuves de course : 100m, 400m, 1500m, 110m haies\n",
    "- √âpreuves de saut : Longueur, Hauteur, Perche\n",
    "- √âpreuves de lancer : Poids, Disque, Javelot\n",
    "- Score total   \n",
    "üí° Les √©preuves sont exprim√©es en diff√©rentes unit√©s (secondes, m√®tres, points). Une standardisation est n√©cessaire avant l'ACP.\n",
    "\n",
    "**Etapes √† suivre**\n",
    "1. Charger le jeu de donn√©es \"decathlon.csv\" et afficher un aper√ßu des donn√©es.\n",
    "1. V√©rifier et traiter les valeurs manquantes si n√©cessaire.\n",
    "1. Standardiser les donn√©es (moyenne = 0, variance = 1) pour √©viter les biais li√©s aux unit√©s diff√©rentes.\n",
    "1. Appliquer une ACP pour r√©duire la dimensionnalit√© des donn√©es.\n",
    "1. Identifier les axes principaux et interpr√©ter les regroupements d‚Äô√©preuves dans l‚Äôespace factoriel.\n",
    "1. Appliquer l‚Äôalgorithme K-Means sur les premi√®res composantes principales obtenues.\n",
    "1. D√©terminer le nombre optimal de clusters √† l‚Äôaide de la m√©thode du coude.\n",
    "1. Visualiser les clusters d‚Äôathl√®tes dans l‚Äôespace r√©duit de l‚ÄôACP.\n",
    "1. Interpr√©ter les groupes form√©s : Quels sont les profils types d‚Äôathl√®tes ? Quelles disciplines sont d√©terminantes pour la classification ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
